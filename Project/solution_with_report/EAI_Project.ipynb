{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5868be54b1ba4c43b57dc82f062aaf1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da7c4033111b434ba4c2fc13e54403a1",
              "IPY_MODEL_70e84d946cec403aadb945da032ff9c5",
              "IPY_MODEL_0bd16e3fef194c0da12956c9298cb8f7"
            ],
            "layout": "IPY_MODEL_60728a24c20c4311b7c44b7cc8b3723a"
          }
        },
        "da7c4033111b434ba4c2fc13e54403a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b9eaf637fae4f339d9b261583733ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6f6176b32f416ead4dfc3104561987",
            "value": "Downloading builder script: 100%"
          }
        },
        "70e84d946cec403aadb945da032ff9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccdbf2a8cf8c43bcb0fd0b572d747f3c",
            "max": 5749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4da81e4b354a46f7b4cbc0dd08941b80",
            "value": 5749
          }
        },
        "0bd16e3fef194c0da12956c9298cb8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6321c1d3a5174d0d882b45ae4322467f",
            "placeholder": "​",
            "style": "IPY_MODEL_71989ffe778b41b79219a05edea21896",
            "value": " 5.75k/5.75k [00:00&lt;00:00, 120kB/s]"
          }
        },
        "60728a24c20c4311b7c44b7cc8b3723a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9eaf637fae4f339d9b261583733ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6f6176b32f416ead4dfc3104561987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccdbf2a8cf8c43bcb0fd0b572d747f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da81e4b354a46f7b4cbc0dd08941b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6321c1d3a5174d0d882b45ae4322467f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71989ffe778b41b79219a05edea21896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4KQ4pLpwA6xx"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class QuantizeAndPruneLayer(nn.Module):\n",
        "#     def __init__(self, k):\n",
        "#         super(QuantizeAndPruneLayer, self).__init__()\n",
        "#         self.k = k\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.quantize_4bit(x)\n",
        "#         x = x.float()\n",
        "#         x = self.k_top_pruning(x, self.k)\n",
        "#         return x\n",
        "\n",
        "#     @staticmethod\n",
        "#     def quantize_4bit(x):\n",
        "#         min_val, max_val = x.min(), x.max()\n",
        "#         x = (x - min_val) / (max_val - min_val)\n",
        "#         x = (x * 15).round().int()\n",
        "#         return x\n",
        "\n",
        "#     @staticmethod\n",
        "#     def k_top_pruning(x, k):\n",
        "#         values, indices = torch.topk(x, k, dim=-1)\n",
        "#         mask = torch.zeros_like(x).scatter_(-1, indices, 1)\n",
        "#         return x * mask\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch"
      ],
      "metadata": {
        "id": "JFUpVuIgSc2z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertForSequenceClassification\n",
        "# from transformers import TrainingArguments, Trainer\n",
        "# import torch\n",
        "\n",
        "# class BertForSequenceClassificationWithPruning(BertForSequenceClassification):\n",
        "#     def __init__(self, config, k=10):\n",
        "#         super(BertForSequenceClassificationWithPruning, self).__init__(config)\n",
        "#         self.quantize_and_prune_layer = QuantizeAndPruneLayer(k)\n",
        "\n",
        "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "#         outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "#         sequence_output = outputs[1]\n",
        "#         sequence_output = self.quantize_and_prune_layer(sequence_output)\n",
        "\n",
        "#         logits = self.classifier(sequence_output)\n",
        "\n",
        "#         probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "#         if labels is not None:\n",
        "#             loss_fct = nn.CrossEntropyLoss()\n",
        "#             loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "#             return loss, probabilities\n",
        "#         else:\n",
        "#             return probabilities\n"
      ],
      "metadata": {
        "id": "nIw-MuFjGUmO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import math\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from transformers.models.bert.modeling_bert import BertAttention, BertSelfAttention, BertForSequenceClassification\n",
        "\n",
        "# class QuantizeAndPruneLayer(nn.Module):\n",
        "#     def __init__(self, k):\n",
        "#         super(QuantizeAndPruneLayer, self).__init__()\n",
        "#         self.k = k\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.quantize_4bit(x)\n",
        "#         x = self.softmax(x)\n",
        "#         x = self.k_top_pruning(x, self.k)\n",
        "#         return x\n",
        "\n",
        "#     @staticmethod\n",
        "#     def quantize_4bit(x):\n",
        "#         x = x.int() >> 4  # Truncate the lower 4 bits\n",
        "#         return x\n",
        "\n",
        "#     @staticmethod\n",
        "#     def softmax(x):\n",
        "#         x = x.float()\n",
        "#         return F.softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def k_top_pruning(x, k):\n",
        "#         values, indices = torch.topk(x, k, dim=-1)\n",
        "#         mask = torch.zeros_like(x).scatter_(-1, indices, 1)\n",
        "#         return x * mask\n",
        "\n",
        "# class QuantizedBertSelfAttention(BertSelfAttention):\n",
        "#     def __init__(self, config, quantize_and_prune_layer):\n",
        "#         super().__init__(config)\n",
        "#         self.quantize_and_prune_layer = quantize_and_prune_layer\n",
        "\n",
        "#     def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "#         mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "#         # if this is a cross-attention layer and we have encoder states, apply the attention on them\n",
        "#         if encoder_hidden_states is not None:\n",
        "#             mixed_key_layer = self.key(encoder_hidden_states)\n",
        "#             mixed_value_layer = self.value(encoder_hidden_states)\n",
        "#             attention_mask = encoder_attention_mask\n",
        "#         else:  # Self-attention\n",
        "#             mixed_key_layer = self.key(hidden_states)\n",
        "#             mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "#         query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "#         key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "\n",
        "#         # Apply quantization and pruning to query and key layers\n",
        "#         query_layer = self.quantize_and_prune_layer(query_layer)\n",
        "#         key_layer = self.quantize_and_prune_layer(key_layer)\n",
        "\n",
        "#         # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "#         attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "#         attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "#         if attention_mask is not None:\n",
        "#             # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "#             attention_scores = attention_scores + attention_mask\n",
        "\n",
        "#         # Normalize the attention scores to probabilities.\n",
        "#         attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "#         # This is actually dropping out entire tokens to attend to, which might\n",
        "#         # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "#         attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "#         # Mask heads if we want to\n",
        "#         if head_mask is not None:\n",
        "#             attention_probs = attention_probs * head_mask\n",
        "\n",
        "#         value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "#         context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "#         context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "#         new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "#         context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "#         outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "#         return outputs\n",
        "\n",
        "\n",
        "# class QuantizedBertAttention(BertAttention):\n",
        "#     def __init__(self, config, quantize_and_prune_layer):\n",
        "#         super().__init__(config)\n",
        "#         self.self = QuantizedBertSelfAttention(config, quantize_and_prune_layer)\n",
        "\n",
        "# class BertForSequenceClassificationWithPruning(BertForSequenceClassification):\n",
        "#     def __init__(self, config, k=10):\n",
        "#         super(BertForSequenceClassificationWithPruning, self).__init__(config)\n",
        "#         self.bert.encoder.layer[0].attention.self = QuantizedBertAttention(config, QuantizeAndPruneLayer(k))\n",
        "\n",
        "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "#         outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "#         sequence_output = outputs[1]\n",
        "\n",
        "#         logits = self.classifier(sequence_output)\n",
        "\n",
        "#         probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "#         if labels is not None:\n",
        "#             loss_fct = nn.CrossEntropyLoss()\n",
        "#             loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "#             return loss, probabilities\n",
        "#         else:\n",
        "#             return probabilities\n"
      ],
      "metadata": {
        "id": "bkVCwkFMPnYb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers.models.bert.modeling_bert import BertAttention, BertSelfAttention, BertForSequenceClassification\n",
        "class MultiLevelBinaryQuantize(nn.Module):\n",
        "    def __init__(self, levels):\n",
        "        super(MultiLevelBinaryQuantize, self).__init__()\n",
        "        self.levels = levels\n",
        "        self.scale = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / self.scale\n",
        "        x = torch.clamp(x, -self.levels, self.levels)\n",
        "        x = torch.round(x)\n",
        "        x = x * self.scale\n",
        "        return x\n",
        "class QuantizeAndPruneLayer(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(QuantizeAndPruneLayer, self).__init__()\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quantize_4bit(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_4bit(x):\n",
        "        x = x.int() >> 4  # Truncate the lower 4 bits\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def k_top_pruning(x, k):\n",
        "        values, indices = torch.topk(x, k, dim=-1)\n",
        "        mask = torch.zeros_like(x).scatter_(-1, indices, 1)\n",
        "        return x * mask\n",
        "\n",
        "class QuantizedBertSelfAttention(BertSelfAttention):\n",
        "    def __init__(self, config, quantize_and_prune_layer):\n",
        "        super().__init__(config)\n",
        "        self.quantize_and_prune_layer = quantize_and_prune_layer\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        if encoder_hidden_states is not None:\n",
        "            mixed_key_layer = self.key(encoder_hidden_states)\n",
        "            mixed_value_layer = self.value(encoder_hidden_states)\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:  # Self-attention\n",
        "            mixed_key_layer = self.key(hidden_states)\n",
        "            mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "\n",
        "        query_layer = self.quantize_and_prune_layer(query_layer).float()\n",
        "        key_layer = self.quantize_and_prune_layer(key_layer).float()\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        attention_probs = self.quantize_and_prune_layer.k_top_pruning(attention_probs, self.quantize_and_prune_layer.k)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        return outputs\n",
        "class BertForSequenceClassificationWithPruning(BertForSequenceClassification):\n",
        "    def __init__(self, config, k=10,levels=15):\n",
        "        super(BertForSequenceClassificationWithPruning, self).__init__(config)\n",
        "        self.bert.encoder.layer[0].attention.self = QuantizedBertSelfAttention(config, QuantizeAndPruneLayer(k))\n",
        "        # self.quantize = MultiLevelBinaryQuantize(levels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[1]\n",
        "\n",
        "        logits = self.classifier(sequence_output)\n",
        "        # logits = self.quantize(logits)\n",
        "\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss, probabilities\n",
        "        else:\n",
        "            return probabilities\n"
      ],
      "metadata": {
        "id": "plxJH7D6RDLI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhNk-pFAmUF9",
        "outputId": "3dc9417b-f629-422c-92c3-83eafddb814d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"glue\",\"mrpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0piRW-h-mlgq",
        "outputId": "7b0f3d08-97b7-4783-ffa8-1f9c7547b1e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRXVAP0QnAsA",
        "outputId": "f0a7c994-561e-43cb-e1f4-907ad4a32a94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIILpzdhIdxW",
        "outputId": "527204a7-af01-45b0-fa1c-5748700c45a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA063IntIqzg",
        "outputId": "12d6d663-7b01-47ad-9b60-6eddd6515c75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from transformers import glue_convert_examples_to_features\n",
        "from transformers import GlueDataset, GlueDataTrainingArguments\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# data_args = GlueDataTrainingArguments(task_name=\"mrpc\", data_dir=\"./mrpc\")\n",
        "\n",
        "mapped_dataset = dataset.map(lambda x: tokenizer(x[\"sentence1\"],x[\"sentence2\"]),batched=True)\n",
        "# train_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"train\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE-iUKsfJswi",
        "outputId": "5dce918a-013d-4c8e-befb-04723c23cc38"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "ZrfmNB1XuJC8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = BertForSequenceClassificationWithPruning.from_pretrained('bert-base-uncased', k=10)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=500,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=mapped_dataset[\"train\"],\n",
        "    eval_dataset=mapped_dataset[\"validation\"],\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "-R0V1SweGqnM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "bc8e3307-a423-442f-ac24-bbfe4ca56375"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassificationWithPruning were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1377/1377 03:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.578100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.411200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1377, training_loss=0.4361565506103338, metrics={'train_runtime': 205.6539, 'train_samples_per_second': 53.507, 'train_steps_per_second': 6.696, 'total_flos': 405324636337200.0, 'train_loss': 0.4361565506103338, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(mapped_dataset[\"test\"])"
      ],
      "metadata": {
        "id": "nbnc0ZBHBoe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "063b9958-67c7-4641-cec7-db982dd04984"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "logits, labels, _ = preds\n",
        "predictions = numpy.argmax(logits, axis=-1)"
      ],
      "metadata": {
        "id": "Y5-GBE2QCEcR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "XSRbGnHpCp-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab7eeeb-741c-4e27-8d3e-961b0bc42dd1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\",\"mrpc\")"
      ],
      "metadata": {
        "id": "5R3Ptm4xC_Fj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5868be54b1ba4c43b57dc82f062aaf1f",
            "da7c4033111b434ba4c2fc13e54403a1",
            "70e84d946cec403aadb945da032ff9c5",
            "0bd16e3fef194c0da12956c9298cb8f7",
            "60728a24c20c4311b7c44b7cc8b3723a",
            "2b9eaf637fae4f339d9b261583733ccb",
            "9f6f6176b32f416ead4dfc3104561987",
            "ccdbf2a8cf8c43bcb0fd0b572d747f3c",
            "4da81e4b354a46f7b4cbc0dd08941b80",
            "6321c1d3a5174d0d882b45ae4322467f",
            "71989ffe778b41b79219a05edea21896"
          ]
        },
        "outputId": "c2bf1a0c-7f71-4274-8d72-87ea02372dbd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5868be54b1ba4c43b57dc82f062aaf1f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=predictions,references=labels)"
      ],
      "metadata": {
        "id": "YZO8oosHEJ51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745ffd90-8904-49df-ff94-e98ddb9d8ef0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8330434782608696, 'f1': 0.8802992518703243}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import torch.nn.init as init\n",
        "import copy\n",
        "import math\n",
        "from transformers.models.bert.modeling_bert import BertAttention, BertSelfAttention, BertForSequenceClassification\n",
        "class MultiLevelBinaryQuantize(nn.Module):\n",
        "    def __init__(self, levels):\n",
        "        super(MultiLevelBinaryQuantize, self).__init__()\n",
        "        self.levels = levels\n",
        "        self.scale = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / self.scale\n",
        "        x = torch.clamp(x, -self.levels, self.levels)\n",
        "        x = torch.round(x)\n",
        "        x = x * self.scale\n",
        "        return x\n",
        "class QuantizeAndPruneLayer(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(QuantizeAndPruneLayer, self).__init__()\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quantize_4bit(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_4bit(x):\n",
        "        x = x.int() >> 4  # Truncate the lower 4 bits\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def k_top_pruning(x, k):\n",
        "        values, indices = torch.topk(x, k, dim=-1)\n",
        "        mask = torch.zeros_like(x).scatter_(-1, indices, 1)\n",
        "        return x * mask\n",
        "\n",
        "class QuantizedBertSelfAttention(BertSelfAttention):\n",
        "    def __init__(self, config, quantize_and_prune_layer):\n",
        "        super().__init__(config)\n",
        "        self.quantize_and_prune_layer = quantize_and_prune_layer\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        if encoder_hidden_states is not None:\n",
        "            mixed_key_layer = self.key(encoder_hidden_states)\n",
        "            mixed_value_layer = self.value(encoder_hidden_states)\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:  # Self-attention\n",
        "            mixed_key_layer = self.key(hidden_states)\n",
        "            mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "\n",
        "        query_layer = self.quantize_and_prune_layer(query_layer).float()\n",
        "        key_layer = self.quantize_and_prune_layer(key_layer).float()\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        attention_probs = self.quantize_and_prune_layer.k_top_pruning(attention_probs, self.quantize_and_prune_layer.k)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        return outputs\n",
        "class BertForSequenceClassificationWithPruning(BertForSequenceClassification):\n",
        "    def __init__(self, config, k=10,levels=15):\n",
        "        super(BertForSequenceClassificationWithPruning, self).__init__(config)\n",
        "        self.bert.encoder.layer[0].attention.self = QuantizedBertSelfAttention(config, QuantizeAndPruneLayer(k))\n",
        "        # self.quantize = MultiLevelBinaryQuantize(levels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[1]\n",
        "\n",
        "        logits = self.classifier(sequence_output)\n",
        "        # logits = self.quantize(logits)\n",
        "\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss, probabilities\n",
        "        else:\n",
        "            return probabilities\n",
        "def gamma_initializer(shape, gain= .5, dtype=None):\n",
        "    return gain * torch.arange(shape,0,-1).float()/shape\n",
        "\n",
        "class Round(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return torch.floor(input + 0.5)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # Gradient is passed through unchanged\n",
        "        return grad_output\n",
        "\n",
        "class HighestPowerOf2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HighestPowerOf2, self).__init__()\n",
        "\n",
        "    def forward(self, n):\n",
        "        n = n.clone().detach().requires_grad_(True)\n",
        "\n",
        "        # Calculate the power\n",
        "        p = torch.log2(n)\n",
        "\n",
        "        # Use custom round operation\n",
        "        p = Round.apply(p)\n",
        "        return 2 ** p\n",
        "\n",
        "class FPQuantize(nn.Module):\n",
        "    def __init__(self, w, f):\n",
        "        super(FPQuantize, self).__init__()\n",
        "        self.w = w\n",
        "        self.f = f\n",
        "        self.i = w - f\n",
        "        self.max_val = float(2 ** (self.i - 1) - 2 ** (-f))\n",
        "        self.min_val = float(-2 ** (self.i - 1))\n",
        "        self.n = float(2 ** f)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = Round.apply(x * self.n + 0.5) / self.n\n",
        "        x = torch.clamp(x, min=self.min_val, max=self.max_val)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Abs(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.abs()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x, = ctx.saved_variables\n",
        "        return grad_output * x.sign()\n",
        "\n",
        "class Binarize(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx._mask = (x.ge(-1) * x.le(1))\n",
        "        clipped = torch.clamp(x, -1, 1)\n",
        "        rounded = torch.sign(clipped).clone().detach()\n",
        "        sp = (rounded - clipped.clone().detach()).detach()\n",
        "        sp.requires_grad = False\n",
        "        return clipped + sp\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        mask = torch.autograd.Variable(ctx._mask.type_as(grad_output.data))\n",
        "        return grad_output * mask\n",
        "\n",
        "class FunRes(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, out_bin, out):\n",
        "        o_bin = out_bin + out\n",
        "        resid = x - out\n",
        "        return o_bin, resid\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_o_bin, grad_resid):\n",
        "        # Initialize gradients for x, out_bin, and out\n",
        "        grad_x = grad_out_bin = grad_out = None\n",
        "\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            # Compute gradient with respect to x\n",
        "            grad_x = grad_resid\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            # Compute gradient with respect to out_bin\n",
        "            grad_out_bin = grad_o_bin\n",
        "        if ctx.needs_input_grad[2]:\n",
        "            # Compute gradient with respect to out\n",
        "            grad_out = grad_o_bin\n",
        "\n",
        "        # Return the gradients, each with respect to its corresponding input\n",
        "        return grad_x, grad_out_bin, grad_out\n",
        "\n",
        "class MLBinarize(nn.Module):\n",
        "    def __init__(self, levels, gamma):\n",
        "        super(MLBinarize, self).__init__()\n",
        "        self.levels = levels\n",
        "        self.gamma = gamma\n",
        "\n",
        "        self.highest_power_of_2 = HighestPowerOf2()\n",
        "\n",
        "    def forward(self, x):\n",
        "        resid = x\n",
        "        out_bin = 0\n",
        "        for l in range(self.levels):\n",
        "            out = Binarize.apply(resid) * self.highest_power_of_2(Abs.apply(self.gamma[l]))\n",
        "            out_bin, resid = FunRes.apply(resid, out_bin, out)\n",
        "        return out_bin\n",
        "\n",
        "class ResidualSign(nn.Module):\n",
        "    def __init__(self, levels=1):\n",
        "        super(ResidualSign, self).__init__()\n",
        "        self.levels = levels\n",
        "        ars = np.arange(self.levels) + 1.0\n",
        "        ars = ars[::-1]\n",
        "        means = ars / np.sum(ars)\n",
        "        self.means = nn.Parameter(torch.tensor(means, dtype=torch.float32))\n",
        "\n",
        "        self.param = {\n",
        "            'levels': self.levels\n",
        "        }\n",
        "        self.type = 'res'\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.means is None:\n",
        "            raise ValueError(\"Call set_means(X) before using the layer.\")\n",
        "\n",
        "        resid = x\n",
        "        out_bin = 0\n",
        "        for l in range(self.levels):\n",
        "            out = Binarize.apply(resid) * Abs.apply(self.means[l])\n",
        "            out_bin, resid = FunRes.apply(resid, out_bin, out)\n",
        "\n",
        "        return out_bin\n",
        "\n",
        "    def _save_to_state_dict(self, destination=None, prefix='', keep_vars=False):\n",
        "        # Save additional attributes along with the state\n",
        "        destination[prefix + 'param'] = self.param\n",
        "        destination[prefix + 'type'] = self.type\n",
        "        super()._save_to_state_dict(destination, prefix, keep_vars)\n",
        "\n",
        "    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs):\n",
        "        self.param = state_dict.pop(prefix + 'param', None)\n",
        "        self.type = state_dict.pop(prefix + 'type', None)\n",
        "        super()._load_from_state_dict(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
        "\n",
        "    def set_means(self, X):\n",
        "        means = np.zeros((self.levels))\n",
        "        means[0] = 1\n",
        "        resid = np.clip(X, -1, 1)\n",
        "        approx = 0\n",
        "        for l in range(self.levels):\n",
        "            m = np.mean(np.absolute(resid))\n",
        "            out = np.sign(resid) * m\n",
        "            approx = approx + out\n",
        "            resid = resid - out\n",
        "            means[l] = m\n",
        "            err = np.mean((approx - np.clip(X, -1, 1))**2)\n",
        "\n",
        "        means = means / np.sum(means)\n",
        "\n",
        "class BinaryInput(nn.Module):\n",
        "    def __init__(self, levels=2):\n",
        "        super(BinaryInput, self).__init__()\n",
        "        self.levels = levels\n",
        "\n",
        "        ars = np.arange(self.levels) + 1.0\n",
        "        ars = ars[::-1]\n",
        "        means = ars / np.sum(ars)\n",
        "        self.means = nn.Parameter(torch.tensor(means, dtype=torch.float32), requires_grad=True)\n",
        "\n",
        "        self.param = {\n",
        "            'levels': self.levels\n",
        "        }\n",
        "        self.type = 'input'\n",
        "\n",
        "    def forward(self, x):\n",
        "        bn_module = MLBinarize(self.levels, self.means)\n",
        "        return bn_module(x)\n",
        "\n",
        "    def _save_to_state_dict(self, destination=None, prefix='', keep_vars=False):\n",
        "        # Save additional attributes along with the state\n",
        "        destination[prefix + 'param'] = self.param\n",
        "        destination[prefix + 'type'] = self.type\n",
        "        super()._save_to_state_dict(destination, prefix, keep_vars)\n",
        "\n",
        "    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs):\n",
        "        self.param = state_dict.pop(prefix + 'param', None)\n",
        "        self.type = state_dict.pop(prefix + 'type', None)\n",
        "        super()._load_from_state_dict(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
        "\n",
        "class FunBinaryWeight(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, weight, gamma):\n",
        "        ctx.save_for_backward(weight, gamma)\n",
        "        clamped_w = gamma * weight\n",
        "        return clamped_w\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        weight, gamma = ctx.saved_tensors\n",
        "\n",
        "        grad_weight = grad_output * gamma  # Gradient with respect to weight\n",
        "        grad_gamma = torch.sum(grad_output * weight)  # Gradient with respect to gamma\n",
        "\n",
        "        return grad_weight, grad_gamma\n",
        "\n",
        "class BinaryLinear(nn.Linear):\n",
        "    def __init__(self, n_in, n_out, w_bits=2, a_bits=2):\n",
        "        super(BinaryLinear, self).__init__(n_in, n_out, bias=False)\n",
        "        self.n_in = n_in\n",
        "        self.n_out = n_out\n",
        "        self.w_levels = w_bits\n",
        "        self.a_levels = a_bits\n",
        "\n",
        "        stdv = 1 / np.sqrt(self.n_in)\n",
        "        w = np.random.normal(loc=0.0, scale=stdv, size=(self.n_in, self.n_out)).astype(np.float32)\n",
        "        self.weight = nn.Parameter(torch.tensor(w))\n",
        "        self.gamma = nn.Parameter(gamma_initializer(self.w_levels, 0.5), requires_grad=True)\n",
        "\n",
        "        self.mlb = MLBinarize(self.w_levels, self.gamma)\n",
        "        self.amlb = ResidualSign(a_bits)\n",
        "\n",
        "    def set_weight(self, weight):\n",
        "        self.weight = nn.Parameter(torch.tensor(weight))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.a_levels > 0:\n",
        "            x = self.amlb(x)\n",
        "        clamped_w = self.mlb(self.weight)\n",
        "        out = F.linear(x, clamped_w, None)\n",
        "        return out\n",
        "\n",
        "\n",
        "class BinaryConv2d(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1,\n",
        "                groups=1, dilation=1, padding_mode='zeros', levels=1):\n",
        "\n",
        "        super(BinaryConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding,\n",
        "                                    dilation=dilation, groups=groups, padding_mode=padding_mode, bias=False)\n",
        "\n",
        "        self.w_levels = levels\n",
        "\n",
        "        if type(kernel_size) is int:\n",
        "            self.k = (kernel_size, kernel_size)\n",
        "        else:\n",
        "            self.k = kernel_size\n",
        "\n",
        "        stdv = 1 / np.sqrt(self.k[0] * self.k[1] * self.in_channels)\n",
        "        w = np.random.normal(loc=0.0, scale=stdv, size=(self.out_channels, self.in_channels, self.k[0], self.k[1])).astype(np.float32)\n",
        "        self.weight = nn.Parameter(torch.tensor(w))\n",
        "        self.gamma = nn.Parameter(gamma_initializer(self.w_levels, 0.5), requires_grad=True)\n",
        "\n",
        "        self.mlb = MLBinarize(self.w_levels, self.gamma)\n",
        "\n",
        "        self.param = {\n",
        "            self.w_levels\n",
        "        }\n",
        "        self.type = 'conv2d'\n",
        "\n",
        "    def set_weight(self, weight):\n",
        "        self.weight = nn.Parameter(torch.tensor(weight))\n",
        "\n",
        "    def forward(self, x):\n",
        "        clamped_w = self.mlb(self.weight)\n",
        "        out = F.conv2d(x, clamped_w, padding=self.padding, stride=self.stride, dilation=self.dilation, groups=self.groups)\n",
        "        return out\n",
        "\n",
        "    def _save_to_state_dict(self, destination=None, prefix='', keep_vars=False):\n",
        "        # Save additional attributes along with the state\n",
        "        destination[prefix + 'param'] = self.param\n",
        "        destination[prefix + 'type'] = self.type\n",
        "        super()._save_to_state_dict(destination, prefix, keep_vars)\n",
        "\n",
        "    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs):\n",
        "        self.param = state_dict.pop(prefix + 'param', None)\n",
        "        self.type = state_dict.pop(prefix + 'type', None)\n",
        "        super()._load_from_state_dict(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
        "\n",
        "def add_quant_op(module, layer_counter, a_bits=8, w_bits=8):\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, nn.Linear):\n",
        "            layer_counter[0] += 1\n",
        "            quant_linear = BinaryLinear(child.in_features, child.out_features,\n",
        "                                        a_bits=a_bits, w_bits=w_bits)\n",
        "\n",
        "            quant_linear.weight.data = child.weight\n",
        "            module._modules[name] = quant_linear\n",
        "        else:\n",
        "            add_quant_op(child, layer_counter, a_bits=a_bits, w_bits=w_bits)\n",
        "\n",
        "\n",
        "def prepare(model, inplace=False, a_bits=8, w_bits=8):\n",
        "    if not inplace:\n",
        "        model = copy.deepcopy(model)\n",
        "    layer_counter = [0]\n",
        "    add_quant_op(model, layer_counter, a_bits=a_bits, w_bits=w_bits)\n",
        "    return model\n",
        "model = BertForSequenceClassificationWithPruning.from_pretrained('bert-base-uncased', k=10)\n",
        "model = prepare(model)"
      ],
      "metadata": {
        "id": "xjup58Knjg9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785e909e-7bd9-4870-c2ad-6b18465cf2ce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassificationWithPruning were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=mapped_dataset[\"train\"],\n",
        "    eval_dataset=mapped_dataset[\"validation\"],\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "xyRxWYLGjxgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "52390678-6779-4390-e35c-60377f57a0cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-3f5d5a4c55db>:161: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n",
            "  x, = ctx.saved_variables\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 501/1377 06:54 < 12:07, 1.20 it/s, Epoch 1.09/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.647800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.639800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.634700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.653300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a3dbb89a080b>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1920\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1922\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2348\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2350\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_deepspeed_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m             \u001b[0;31m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2899\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2901\u001b[0;31m             self.model.save_pretrained(\n\u001b[0m\u001b[1;32m   2902\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2903\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2158\u001b[0m             \u001b[0mweights_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADAPTER_SAFE_WEIGHTS_NAME\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msafe_serialization\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mADAPTER_WEIGHTS_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0mshards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshard_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_shard_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_shard_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0;31m# Clean the folder from a previous save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mshard_checkpoint\u001b[0;34m(state_dict, max_shard_size, weights_name)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mstorage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_tensor_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;31m# If a `weight` shares the same underlying storage as another tensor, we put `weight` in the same `block`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mid_tensor_storage\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moverlapping\u001b[0m \u001b[0mlifetimes\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;31m# NOTE: xla tensors dont have storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# use some other unique id to distinguish.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import torch.nn.init as init\n",
        "import copy\n",
        "import math\n",
        "from transformers.models.bert.modeling_bert import BertAttention, BertSelfAttention, BertForSequenceClassification\n",
        "class MultiLevelBinaryQuantize(nn.Module):\n",
        "    def __init__(self, levels):\n",
        "        super(MultiLevelBinaryQuantize, self).__init__()\n",
        "        self.levels = levels\n",
        "        self.scale = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / self.scale\n",
        "        x = torch.clamp(x, -self.levels, self.levels)\n",
        "        x = torch.round(x)\n",
        "        x = x * self.scale\n",
        "        return x\n",
        "class QuantizeAndPruneLayer(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(QuantizeAndPruneLayer, self).__init__()\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quantize_4bit(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_4bit(x):\n",
        "        x = x.int() >> 64  # Truncate the lower 4 bits\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def k_top_pruning(x, k):\n",
        "        values, indices = torch.topk(x, k, dim=-1)\n",
        "        mask = torch.zeros_like(x).scatter_(-1, indices, 1)\n",
        "        return x * mask\n",
        "\n",
        "class QuantizedBertSelfAttention(BertSelfAttention):\n",
        "    def __init__(self, config, quantize_and_prune_layer):\n",
        "        super().__init__(config)\n",
        "        self.quantize_and_prune_layer = quantize_and_prune_layer\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        if encoder_hidden_states is not None:\n",
        "            mixed_key_layer = self.key(encoder_hidden_states)\n",
        "            mixed_value_layer = self.value(encoder_hidden_states)\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:  # Self-attention\n",
        "            mixed_key_layer = self.key(hidden_states)\n",
        "            mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "\n",
        "        query_layer = self.quantize_and_prune_layer(query_layer).float()\n",
        "        key_layer = self.quantize_and_prune_layer(key_layer).float()\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        attention_probs = self.quantize_and_prune_layer.k_top_pruning(attention_probs, self.quantize_and_prune_layer.k)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        return outputs\n",
        "class BertForSequenceClassificationWithPruning(BertForSequenceClassification):\n",
        "    def __init__(self, config, k=10,levels=15):\n",
        "        super(BertForSequenceClassificationWithPruning, self).__init__(config)\n",
        "        self.bert.encoder.layer[0].attention.self = QuantizedBertSelfAttention(config, QuantizeAndPruneLayer(k))\n",
        "        # self.quantize = MultiLevelBinaryQuantize(levels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[1]\n",
        "\n",
        "        logits = self.classifier(sequence_output)\n",
        "        # logits = self.quantize(logits)\n",
        "\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss, probabilities\n",
        "        else:\n",
        "            return probabilities\n",
        "class Round(Function):\n",
        "    @staticmethod\n",
        "    def forward(self, input):\n",
        "        sign = torch.sign(input)\n",
        "        output = sign * torch.floor(torch.abs(input) + 0.5)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(self, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return grad_input\n",
        "\n",
        "class FunLSQ(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, weight, alpha, g, Qn, Qp, per_channel=False):\n",
        "        #LEARNED STEP SIZE QUANTIZATION\n",
        "        ctx.save_for_backward(weight, alpha)\n",
        "        ctx.other = g, Qn, Qp, per_channel\n",
        "        if per_channel:\n",
        "            sizes = weight.size()\n",
        "            weight = weight.contiguous().view(weight.size()[0], -1)\n",
        "            weight = torch.transpose(weight, 0, 1)\n",
        "            alpha = torch.broadcast_to(alpha, weight.size())\n",
        "            w_q = Round.apply(torch.div(weight, alpha).clamp(Qn, Qp))\n",
        "            w_q = w_q * alpha\n",
        "            w_q = torch.transpose(w_q, 0, 1)\n",
        "            w_q = w_q.contiguous().view(sizes)\n",
        "        else:\n",
        "            w_q = Round.apply(torch.div(weight, alpha).clamp(Qn, Qp))\n",
        "            w_q = w_q * alpha\n",
        "        return w_q\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_weight):\n",
        "        #LEARNED STEP SIZE QUANTIZATION\n",
        "        weight, alpha = ctx.saved_tensors\n",
        "        g, Qn, Qp, per_channel = ctx.other\n",
        "        if per_channel:\n",
        "            sizes = weight.size()\n",
        "            weight = weight.contiguous().view(weight.size()[0], -1)\n",
        "            weight = torch.transpose(weight, 0, 1)\n",
        "            alpha = torch.broadcast_to(alpha, weight.size())\n",
        "            q_w = weight / alpha\n",
        "            q_w = torch.transpose(q_w, 0, 1)\n",
        "            q_w = q_w.contiguous().view(sizes)\n",
        "        else:\n",
        "            q_w = weight / alpha\n",
        "        smaller = (q_w < Qn).float()\n",
        "        bigger = (q_w > Qp).float()\n",
        "        between = 1.0 - smaller -bigger\n",
        "        if per_channel:\n",
        "            grad_alpha = ((smaller * Qn + bigger * Qp +\n",
        "                between * Round.apply(q_w) - between * q_w)*grad_weight * g)\n",
        "            grad_alpha = grad_alpha.contiguous().view(grad_alpha.size()[0], -1).sum(dim=1)\n",
        "        else:\n",
        "            grad_alpha = ((smaller * Qn + bigger * Qp +\n",
        "                between * Round.apply(q_w) - between * q_w)*grad_weight * g).sum().unsqueeze(dim=0) #?\n",
        "        grad_weight = between * grad_weight\n",
        "        return grad_weight, grad_alpha, None, None, None, None\n",
        "\n",
        "def grad_scale(x, scale):\n",
        "    y = x\n",
        "    y_grad = x * scale\n",
        "    return (y - y_grad).detach() + y_grad\n",
        "\n",
        "def round_pass(x):\n",
        "    y = x.round()\n",
        "    y_grad = x\n",
        "    return (y - y_grad).detach() + y_grad\n",
        "\n",
        "class LSQActivationQuantizer(nn.Module):\n",
        "    def __init__(self, a_bits, all_positive=False, batch_init = 20):\n",
        "        #activations per-channel\n",
        "        super(LSQActivationQuantizer, self).__init__()\n",
        "        self.a_bits = a_bits\n",
        "        self.all_positive = all_positive\n",
        "        self.batch_init = batch_init\n",
        "        if self.all_positive:\n",
        "            # unsigned activation is quantized to [0, 2^b-1]\n",
        "            self.Qn = 0\n",
        "            self.Qp = 2 ** self.a_bits - 1\n",
        "        else:\n",
        "            # signed weight/activation is quantized to [-2^(b-1), 2^(b-1)-1]\n",
        "            self.Qn = - 2 ** (self.a_bits - 1)\n",
        "            self.Qp = 2 ** (self.a_bits - 1) - 1\n",
        "        self.s = torch.nn.Parameter(torch.ones(1), requires_grad=True)  #V2\n",
        "        self.init_state = 0\n",
        "\n",
        "    def forward(self, activation):\n",
        "        if self.a_bits == 32:\n",
        "            q_a = activation\n",
        "        elif self.a_bits == 1:\n",
        "            print('！Binary quantization is not supported ！')\n",
        "            assert self.a_bits != 1\n",
        "        else:\n",
        "            if self.init_state==0:\n",
        "                self.g = 1.0/math.sqrt(activation.numel() * self.Qp)\n",
        "                self.init_state += 1\n",
        "            q_a = FunLSQ.apply(activation, self.s, self.g, self.Qn, self.Qp)\n",
        "\n",
        "        return q_a\n",
        "\n",
        "class LSQWeightQuantizer(nn.Module):\n",
        "    def __init__(self, w_bits, all_positive=False, per_channel=False, batch_init = 20):\n",
        "        super(LSQWeightQuantizer, self).__init__()\n",
        "        self.w_bits = w_bits\n",
        "        self.all_positive = all_positive\n",
        "        self.batch_init = batch_init\n",
        "        if self.all_positive:\n",
        "            # unsigned activation is quantized to [0, 2^b-1]\n",
        "            self.Qn = 0\n",
        "            self.Qp = 2 ** w_bits - 1\n",
        "        else:\n",
        "            # signed weight/activation is quantized to [-2^(b-1), 2^(b-1)-1]\n",
        "            self.Qn = - 2 ** (w_bits - 1)\n",
        "            self.Qp = 2 ** (w_bits - 1) - 1\n",
        "        self.per_channel = per_channel\n",
        "        self.s = torch.nn.Parameter(torch.ones(1), requires_grad=True)\n",
        "        self.init_state = 0\n",
        "\n",
        "    def forward(self, weight):\n",
        "        if self.init_state==0:\n",
        "            self.g = 1.0/math.sqrt(weight.numel() * self.Qp)\n",
        "            if self.per_channel:\n",
        "                weight_tmp = weight.detach().contiguous().view(weight.size()[0], -1)\n",
        "                self.s.data = torch.mean(torch.abs(weight_tmp), dim=1)*2/(math.sqrt(self.Qp))\n",
        "            else:\n",
        "                self.s.data = torch.mean(torch.abs(weight.detach()))*2/(math.sqrt(self.Qp))\n",
        "            self.init_state += 1\n",
        "        elif self.init_state<self.batch_init:\n",
        "            if self.per_channel:\n",
        "                weight_tmp = weight.detach().contiguous().view(weight.size()[0], -1)\n",
        "                self.s.data = 0.9*self.s.data + 0.1*torch.mean(torch.abs(weight_tmp), dim=1)*2/(math.sqrt(self.Qp))\n",
        "            else:\n",
        "                self.s.data = 0.9*self.s.data + 0.1*torch.mean(torch.abs(weight.detach()))*2/(math.sqrt(self.Qp))\n",
        "            self.init_state += 1\n",
        "        elif self.init_state==self.batch_init:\n",
        "            self.init_state += 1\n",
        "        if self.w_bits == 32:\n",
        "            w_q = weight\n",
        "        elif self.w_bits == 1:\n",
        "            print('！Binary quantization is not supported ！')\n",
        "            assert self.w_bits != 1\n",
        "        else:\n",
        "            w_q = FunLSQ.apply(weight, self.s, self.g, self.Qn, self.Qp, self.per_channel)\n",
        "\n",
        "        return w_q\n",
        "\n",
        "class QuantConv2d(nn.Conv2d):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 dilation=1,\n",
        "                 groups=1,\n",
        "                 bias=True,\n",
        "                 padding_mode='zeros',\n",
        "                 a_bits=8,\n",
        "                 w_bits=8,\n",
        "                 quant_inference=False,\n",
        "                 all_positive=False,\n",
        "                 per_channel=False,\n",
        "                 batch_init = 20):\n",
        "        super(QuantConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups,\n",
        "                                          bias, padding_mode)\n",
        "        self.quant_inference = quant_inference\n",
        "        self.activation_quantizer = LSQActivationQuantizer(a_bits=a_bits, all_positive=all_positive,batch_init = batch_init)\n",
        "        self.weight_quantizer = LSQWeightQuantizer(w_bits=w_bits, all_positive=all_positive, per_channel=per_channel,batch_init = batch_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        quant_input = self.activation_quantizer(input)\n",
        "        if not self.quant_inference:\n",
        "            quant_weight = self.weight_quantizer(self.weight)\n",
        "        else:\n",
        "            quant_weight = self.weight\n",
        "\n",
        "        output = F.conv2d(quant_input, quant_weight, self.bias, self.stride, self.padding, self.dilation,\n",
        "                          self.groups)\n",
        "        return output\n",
        "\n",
        "\n",
        "class QuantConvTranspose2d(nn.ConvTranspose2d):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 output_padding=0,\n",
        "                 dilation=1,\n",
        "                 groups=1,\n",
        "                 bias=True,\n",
        "                 padding_mode='zeros',\n",
        "                 a_bits=8,\n",
        "                 w_bits=8,\n",
        "                 quant_inference=False,\n",
        "                 all_positive=False,\n",
        "                 per_channel=False,\n",
        "                 batch_init = 20):\n",
        "        super(QuantConvTranspose2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, output_padding,\n",
        "                                                   dilation, groups, bias, padding_mode)\n",
        "        self.quant_inference = quant_inference\n",
        "        self.activation_quantizer = LSQActivationQuantizer(a_bits=a_bits, all_positive=all_positive,batch_init = batch_init)\n",
        "        self.weight_quantizer = LSQWeightQuantizer(w_bits=w_bits, all_positive=all_positive, per_channel=per_channel,batch_init = batch_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        quant_input = self.activation_quantizer(input)\n",
        "        if not self.quant_inference:\n",
        "            quant_weight = self.weight_quantizer(self.weight)\n",
        "        else:\n",
        "            quant_weight = self.weight\n",
        "        output = F.conv_transpose2d(quant_input, quant_weight, self.bias, self.stride, self.padding, self.output_padding,\n",
        "                                    self.groups, self.dilation)\n",
        "        return output\n",
        "\n",
        "\n",
        "class QuantLinear(nn.Linear):\n",
        "    def __init__(self,\n",
        "                 in_features,\n",
        "                 out_features,\n",
        "                 bias=True,\n",
        "                 a_bits=8,\n",
        "                 w_bits=8,\n",
        "                 quant_inference=False,\n",
        "                 all_positive=False,\n",
        "                 per_channel=False,\n",
        "                 batch_init = 20):\n",
        "        super(QuantLinear, self).__init__(in_features, out_features, bias)\n",
        "        self.quant_inference = quant_inference\n",
        "        self.activation_quantizer = LSQActivationQuantizer(a_bits=a_bits, all_positive=all_positive,batch_init = batch_init)\n",
        "        self.weight_quantizer = LSQWeightQuantizer(w_bits=w_bits, all_positive=all_positive, per_channel=per_channel,batch_init = batch_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        quant_input = self.activation_quantizer(input)\n",
        "        if not self.quant_inference:\n",
        "            quant_weight = self.weight_quantizer(self.weight)\n",
        "        else:\n",
        "            quant_weight = self.weight\n",
        "        output = F.linear(quant_input, quant_weight, self.bias)\n",
        "        return output\n",
        "\n",
        "class QuantBatchNorm2d(nn.BatchNorm2d):\n",
        "    def __init__(self, num_features: int, eps: float = 0.00001, momentum: float = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None, w_bits=8, all_positive=False, batch_init=20) -> None:\n",
        "        super(QuantBatchNorm2d, self).__init__(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
        "\n",
        "        self.w_bits = w_bits\n",
        "\n",
        "        self.quant_w = LSQWeightQuantizer(w_bits=w_bits, all_positive=all_positive, per_channel=False, batch_init = batch_init)\n",
        "        self.quant_b = LSQWeightQuantizer(w_bits=w_bits, all_positive=all_positive, per_channel=False, batch_init = batch_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.weight is not None:\n",
        "            self.weight.data = self.quant_w(self.weight)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data = self.quant_b(self.bias)\n",
        "\n",
        "        return super(QuantBatchNorm2d, self).forward(x)\n",
        "\n",
        "    def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
        "        # Save additional attributes along with the state\n",
        "        state = super(QuantBatchNorm2d, self).state_dict(destination, prefix, keep_vars)\n",
        "        state[prefix + 'param'] = {\n",
        "            'w_bits': self.w_bits\n",
        "        }\n",
        "        state[prefix + 'type'] = 'batchnorm2d'\n",
        "        return state\n",
        "\n",
        "class QuantBatchNorm1d(nn.BatchNorm1d):\n",
        "    def __init__(self, num_features: int, eps: float = 0.00001, momentum: float = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None, w_bits=8, all_positive=False, batch_init=20) -> None:\n",
        "        super(QuantBatchNorm1d, self).__init__(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
        "\n",
        "        self.w_bits = w_bits\n",
        "\n",
        "        self.quant_w = LSQWeightQuantizer(w_bits=w_bits, all_positive=all_positive, per_channel=False, batch_init = batch_init)\n",
        "        self.quant_b = LSQWeightQuantizer(w_bits=w_bits, all_positive=all_positive, per_channel=False, batch_init = batch_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.weight is not None:\n",
        "            self.weight.data = self.quant_w(self.weight)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data = self.quant_b(self.bias)\n",
        "\n",
        "        return super(QuantBatchNorm1d, self).forward(x)\n",
        "\n",
        "    def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
        "        # Save additional attributes along with the state\n",
        "        state = super(QuantBatchNorm1d, self).state_dict(destination, prefix, keep_vars)\n",
        "        state[prefix + 'param'] = {\n",
        "            'w_bits': self.w_bits\n",
        "        }\n",
        "        state[prefix + 'type'] = 'batchnorm1d'\n",
        "        return state\n",
        "\n",
        "def add_quant_op(module, layer_counter, a_bits=8, w_bits=8,\n",
        "                 quant_inference=False, all_positive=False, per_channel=False,\n",
        "                 batch_init = 20, length=1):\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, nn.Conv2d):\n",
        "            layer_counter[0] += 1\n",
        "            if layer_counter[0] > 1:\n",
        "                if child.bias is not None:\n",
        "                    quant_conv = QuantConv2d(child.in_channels, child.out_channels,\n",
        "                                             child.kernel_size, stride=child.stride,\n",
        "                                             padding=child.padding, dilation=child.dilation,\n",
        "                                             groups=child.groups, bias=True, padding_mode=child.padding_mode,\n",
        "                                             a_bits=a_bits, w_bits=w_bits, quant_inference=quant_inference,\n",
        "                                             all_positive=all_positive, per_channel=per_channel, batch_init = batch_init)\n",
        "                    quant_conv.bias.data = child.bias\n",
        "                else:\n",
        "                    quant_conv = QuantConv2d(child.in_channels, child.out_channels,\n",
        "                                             child.kernel_size, stride=child.stride,\n",
        "                                             padding=child.padding, dilation=child.dilation,\n",
        "                                             groups=child.groups, bias=False, padding_mode=child.padding_mode,\n",
        "                                             a_bits=a_bits, w_bits=w_bits, quant_inference=quant_inference,\n",
        "                                             all_positive=all_positive, per_channel=per_channel, batch_init = batch_init)\n",
        "                quant_conv.weight.data = child.weight\n",
        "                module._modules[name] = quant_conv\n",
        "        elif isinstance(child, nn.ConvTranspose2d):\n",
        "            layer_counter[0] += 1\n",
        "            if layer_counter[0] > 1:\n",
        "                if child.bias is not None:\n",
        "                    quant_conv_transpose = QuantConvTranspose2d(child.in_channels,\n",
        "                                                                child.out_channels,\n",
        "                                                                child.kernel_size,\n",
        "                                                                stride=child.stride,\n",
        "                                                                padding=child.padding,\n",
        "                                                                output_padding=child.output_padding,\n",
        "                                                                dilation=child.dilation,\n",
        "                                                                groups=child.groups,\n",
        "                                                                bias=True,\n",
        "                                                                padding_mode=child.padding_mode,\n",
        "                                                                a_bits=a_bits,\n",
        "                                                                w_bits=w_bits,\n",
        "                                                                quant_inference=quant_inference,\n",
        "                                             all_positive=all_positive, per_channel=per_channel, batch_init = batch_init)\n",
        "                    quant_conv_transpose.bias.data = child.bias\n",
        "                else:\n",
        "                    quant_conv_transpose = QuantConvTranspose2d(child.in_channels,\n",
        "                                                                child.out_channels,\n",
        "                                                                child.kernel_size,\n",
        "                                                                stride=child.stride,\n",
        "                                                                padding=child.padding,\n",
        "                                                                output_padding=child.output_padding,\n",
        "                                                                dilation=child.dilation,\n",
        "                                                                groups=child.groups, bias=False,\n",
        "                                                                padding_mode=child.padding_mode,\n",
        "                                                                a_bits=a_bits,\n",
        "                                                                w_bits=w_bits,\n",
        "                                                                quant_inference=quant_inference,\n",
        "                                             all_positive=all_positive, per_channel=per_channel, batch_init = batch_init)\n",
        "                quant_conv_transpose.weight.data = child.weight\n",
        "                module._modules[name] = quant_conv_transpose\n",
        "        elif isinstance(child, nn.Linear):\n",
        "            layer_counter[0] += 1\n",
        "            if layer_counter[0] > 1 and layer_counter[0] < length:\n",
        "                if child.bias is not None:\n",
        "                    quant_linear = QuantLinear(child.in_features, child.out_features,\n",
        "                                               bias=True, a_bits=a_bits, w_bits=w_bits,\n",
        "                                               quant_inference=quant_inference,\n",
        "                                             all_positive=all_positive, per_channel=per_channel, batch_init = batch_init)\n",
        "                    quant_linear.bias.data = child.bias\n",
        "                else:\n",
        "                    quant_linear = QuantLinear(child.in_features, child.out_features,\n",
        "                                               bias=False, a_bits=a_bits, w_bits=w_bits,\n",
        "                                               quant_inference=quant_inference,\n",
        "                                             all_positive=all_positive, per_channel=per_channel, batch_init = batch_init)\n",
        "                quant_linear.weight.data = child.weight\n",
        "                module._modules[name] = quant_linear\n",
        "        else:\n",
        "            add_quant_op(child, layer_counter, a_bits=a_bits, w_bits=w_bits,\n",
        "                         quant_inference=quant_inference, all_positive=all_positive, per_channel=per_channel, batch_init = batch_init)\n",
        "\n",
        "\n",
        "def prepare(model, inplace=False, a_bits=8, w_bits=8, quant_inference=False,\n",
        "            all_positive=False, per_channel=False, batch_init = 20):\n",
        "    if not inplace:\n",
        "        model = copy.deepcopy(model)\n",
        "    layer_counter = [0]\n",
        "    l = len(list(model.named_children()))\n",
        "    add_quant_op(model, layer_counter, a_bits=a_bits, w_bits=w_bits,\n",
        "                 quant_inference=quant_inference, all_positive=all_positive,\n",
        "                 per_channel=per_channel, batch_init = batch_init, length=l)\n",
        "    return model\n",
        "model = BertForSequenceClassificationWithPruning.from_pretrained('bert-base-uncased', k=10)\n",
        "model = prepare(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0SGGfQmB7Wh",
        "outputId": "40fc6ccf-ff65-40e8-d856-f4ca970a9570"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassificationWithPruning were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=mapped_dataset[\"train\"],\n",
        "    eval_dataset=mapped_dataset[\"validation\"],\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "NE9j6LTeCOGe",
        "outputId": "d4583934-f6c8-4489-c4bd-c67af55c5fd2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1377/1377 03:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.650400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.594400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.579700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.531100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.420200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.336000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.392800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.325800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.125800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.122100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1377, training_loss=0.35207031599057265, metrics={'train_runtime': 194.8468, 'train_samples_per_second': 56.475, 'train_steps_per_second': 7.067, 'total_flos': 405324636337200.0, 'train_loss': 0.35207031599057265, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\",\"mrpc\")\n",
        "preds = trainer.predict(mapped_dataset[\"test\"])\n",
        "logits, labels, _ = preds\n",
        "predictions = numpy.argmax(logits, axis=-1)\n",
        "metric.compute(predictions=predictions,references=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JmxnvSYxDNNv",
        "outputId": "96c76aba-39c8-479a-bcd8-d7e95940c700"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7942028985507247, 'f1': 0.850147741663149}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}
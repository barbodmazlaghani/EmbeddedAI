{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_quantize(x, w, f):\n",
    "    \"\"\"\n",
    "    fixed point post quantization.\n",
    "    Args:\n",
    "        x: floating point (can be list) 32 bit input\n",
    "        w: bit width of the target fixed point\n",
    "        f: fraction bit width of the target fixed point\n",
    "    Returns:\n",
    "        the desired fixed point quantized of the input x\n",
    "    \"\"\"\n",
    "    i = w - f\n",
    "    max = float(2 ** (i - 1) - 2 ** (-f))\n",
    "    min = float(-2 ** (i - 1))\n",
    "    n = float(2 ** f)\n",
    "    xx = np.floor(x * n + 0.5) / n\n",
    "    clipped = np.clip(xx, a_min=min, a_max=max)\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FPToHex(x, w = 8, f = 7):\n",
    "    \"\"\"\n",
    "    Converts a given Fixed point number to its Hex representation.\n",
    "    Args:\n",
    "        x: fixed point having w bits and f bits fraction input\n",
    "        w: bit width of the input\n",
    "        f: fraction bit width of the input\n",
    "    Returns:\n",
    "        Hex representation of input\n",
    "    \"\"\"\n",
    "    x_fix = x\n",
    "    x_fix = x_fix * pow(2, f)\n",
    "    x_fix = int(x_fix)\n",
    "    if(x_fix < 0):\n",
    "        binary = bin(x_fix+(1<<w))\n",
    "    else:\n",
    "        binary = bin(x_fix)\n",
    "    return hex(int(binary, 2))[2:]\n",
    "\n",
    "def WriteFixPToFile(file_name, data_fp, w = 8, f = 7, mode = \"w\"):\n",
    "    \"\"\"\n",
    "    Writes given Fixed point numbers specified by w bits width and f bits fraction to the given file name.\n",
    "    Args:\n",
    "        file_name: file name to save the output\n",
    "        data_fp: fixed point list having w bits and f bits fraction input\n",
    "        w: bit width of the input\n",
    "        f: fraction bit width of the input\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(file_name, mode) as file:\n",
    "        for i in range(data_fp.shape[0]):\n",
    "            file.write(str(FPToHex(data_fp[i], w=w, f=f))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below function if needed (like verifying outputs or debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twos_complement(bin_num):\n",
    "    \"\"\"\n",
    "    calculates the 2's complement of the given binary number.\n",
    "    Args:\n",
    "        bin_num: binary number in string format\n",
    "    Returns:\n",
    "        the binary representation after performing 2's complement\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform 2's complement on the binary number\n",
    "    flipped = ''\n",
    "    for bit in bin_num:\n",
    "        flipped += '0' if bit == '1' else '1'\n",
    "    comp_num = int(flipped, 2) + 1\n",
    "\n",
    "    return bin(comp_num)[2:].zfill(len(bin_num))\n",
    "\n",
    "def fixed_point_to_float(bin_num, w=16, f=14):\n",
    "    \"\"\"\n",
    "    Converts a fixed point number given in binary representation to its decimal floating point.\n",
    "    Args:\n",
    "        bin_num: binary number in string format\n",
    "        w: bit width of the input\n",
    "        f: fraction bit width of the input\n",
    "    Returns:\n",
    "        decimal floating point\n",
    "    \"\"\"\n",
    "        # Check if the number is negative\n",
    "    sign_bit = int(bin_num[0])\n",
    "    if sign_bit:\n",
    "        bin_num = twos_complement(bin_num, w, f)\n",
    "\n",
    "    # Split the binary number into integer and fractional parts\n",
    "    if f > 0:\n",
    "        if f == w:\n",
    "            float_num = int(bin_num, 2) / 2**f\n",
    "        else:\n",
    "            int_part = int(bin_num[:-f], 2)\n",
    "            frac_part = int(bin_num[-f:], 2) / 2**f\n",
    "            float_num = int_part + frac_part\n",
    "    else:\n",
    "        int_part = int(bin_num, 2)\n",
    "        float_num = int_part\n",
    "\n",
    "    # Apply the sign to the floating point number if it was negative\n",
    "    if sign_bit:\n",
    "        float_num = -float_num\n",
    "\n",
    "    return float_num\n",
    "\n",
    "def hex_to_fixed_point_decimal(hex_value, w, f):\n",
    "    \"\"\"\n",
    "    Converts a fixed point number given in hex representation to its decimal floating point.\n",
    "    Args:\n",
    "        hex_value: hex number in string format\n",
    "        w: bit width of the input\n",
    "        f: fraction bit width of the input\n",
    "    Returns:\n",
    "        decimal floating point\n",
    "    \"\"\"\n",
    "    binary_value = bin(int(hex_value, 16))[2:]\n",
    "\n",
    "    # # Determine the sign bit\n",
    "    binary_value = binary_value.zfill(w)\n",
    "\n",
    "    # return decimal_value\n",
    "    return fixed_point_to_float(binary_value, w, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and normalize data images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SAPCE_DIM = 32\n",
    "LATENT_SPACE_WIDTH = 4\n",
    "LATENT_SAPCE_HEIGHT = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape images to one dimensional shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the autoencoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(x_train.shape[1],))\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(LATENT_SAPCE_DIM, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(x_train.shape[1], activation='sigmoid')(decoded)\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = keras.Input(shape=(LATENT_SAPCE_DIM,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-3](encoded_input)\n",
    "decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
    "decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the output of the decoder from x_test input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display the initial images and their corresponding decoded ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display the images in latent space (output of encoder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape((LATENT_SPACE_WIDTH, LATENT_SAPCE_HEIGHT)).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply noise to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display noisy images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model based on noisy input and real target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = keras.Input(shape=(LATENT_SAPCE_DIM,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-3](encoded_input)\n",
    "decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
    "decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test_noisy)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the noisy images and their corresponding denoised one using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"autoencoder.h5\")\n",
    "encoder.save(\"encoder.h5\")\n",
    "decoder.save(\"decoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot histogram of the weights of first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights = encoder.layers[1].get_weights()\n",
    "\n",
    "# Plot the weight distribution\n",
    "if layer_weights:\n",
    "    weights = layer_weights[0] \n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(weights.flatten(), bins=30, alpha=0.5, color='b', label='Weight Distribution')\n",
    "    plt.title(f'Weight Distribution of Layer {0}')\n",
    "    plt.xlabel('Weight Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post quantize input and output to 16 bits width having 14 bits fraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = fp_quantize(x_train, 17, 14)\n",
    "x_test2 = fp_quantize(x_test, 17, 14)\n",
    "x_train_noisy_2 = fp_quantize(x_train_noisy, 17, 14)\n",
    "x_test_noisy_2 = fp_quantize(x_test_noisy, 17, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the quantization model using \"qkeras\" model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(x_train2.shape[1],))\n",
    "encoded = QDense(128, kernel_quantizer=quantized_bits(8, 1, alpha=1), bias_quantizer=quantized_bits(8, 1, alpha=1))(input_img)\n",
    "encoded = QActivation(activation=quantized_relu(8, 1))(encoded)\n",
    "encoded = QDense(64, kernel_quantizer=quantized_bits(8, 1, alpha=1), bias_quantizer=quantized_bits(8, 1, alpha=1))(encoded)\n",
    "encoded = QActivation(activation=quantized_relu(8, 1))(encoded)\n",
    "encoded = QDense(LATENT_SAPCE_DIM, kernel_quantizer=quantized_bits(16, 2, alpha=1), bias_quantizer=quantized_bits(16, 2, alpha=1))(encoded)\n",
    "encoded = QActivation(activation=quantized_relu(16, 2))(encoded)\n",
    "\n",
    "decoded = QDense(64, kernel_quantizer=quantized_bits(8, 1, alpha=1), bias_quantizer=quantized_bits(8, 1, alpha=1))(encoded)\n",
    "decoded = QActivation(activation=quantized_relu(8, 1))(decoded)\n",
    "decoded = QDense(128, kernel_quantizer=quantized_bits(8, 1, alpha=1), bias_quantizer=quantized_bits(8, 1, alpha=1))(decoded)\n",
    "decoded = QActivation(activation=quantized_relu(8, 1))(decoded)\n",
    "decoded = QDense(x_train2.shape[1], kernel_quantizer=quantized_bits(16, 2, alpha=1), bias_quantizer=quantized_bits(16, 2, alpha=1), activation='sigmoid')(decoded)\n",
    "\n",
    "qautoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model (Quantization Aware Training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history = qautoencoder.fit(x_train_noisy_2, x_train2,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy_2, x_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qencoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = keras.Input(shape=(LATENT_SAPCE_DIM,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = qautoencoder.layers[-5](encoded_input)\n",
    "decoder_layer = qautoencoder.layers[-4](decoder_layer)\n",
    "decoder_layer = qautoencoder.layers[-3](decoder_layer)\n",
    "decoder_layer = qautoencoder.layers[-2](decoder_layer)\n",
    "decoder_layer = qautoencoder.layers[-1](decoder_layer)\n",
    "# Create the decoder model\n",
    "qdecoder = keras.Model(encoded_input, decoder_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the outputs of the autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = qencoder.predict(x_test_noisy_2)\n",
    "decoded_imgs = qdecoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display the noisy inputs and their corresponding output using the quantized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy_2[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"qautoencoder.h5\")\n",
    "qencoder.save(\"qencoder.h5\")\n",
    "qdecoder.save(\"qdecoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save Weights as Fixed Point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "qencoder = keras.models.load_model('qencoder.h5', custom_objects=co)\n",
    "qencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_noisy_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qencoder.predict(np.array([x_test2[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteFixPToFile(\"input.txt\", x_test2[0], 17, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('weights'):\n",
    "    os.mkdir('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(qencoder.layers):\n",
    "    weights = layer.get_weights()        \n",
    "    if weights and len(weights) > 0:\n",
    "        w_per_neuron = weights[0].shape[0]\n",
    "        w = np.einsum(\"ij->ji\", weights[0]).reshape(-1,)\n",
    "        b = weights[1].reshape(-1,)\n",
    "        separate_weights = [np.concatenate((w[c:c+w_per_neuron], b[int(c/w_per_neuron):int(c/w_per_neuron)+1]), axis=0) for c in range(0, len(w), w_per_neuron)]\n",
    "\n",
    "        width, f = (17, 14) if layer.name == 'last' else (9, 7) \n",
    "        for n, s in enumerate(separate_weights):\n",
    "            WriteFixPToFile(f\"weights/layer_{i + 1}_{n + 1}_w.txt\", s, width, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
